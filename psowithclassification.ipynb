{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "psowithclassification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukjcXOG8plak"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.datasets import make_classification\n",
        "RANDOM_STATE = 8\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from matplotlib import pyplot\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing and Splitting the dataset\n",
        "dataset = pd.read_csv('gini_fs_final.csv')\n",
        "df = dataset.iloc[ : , :]\n",
        "#print(df.head())\n",
        "X, y = dataset.iloc[:, :-1], dataset.iloc[:, -1]\n",
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBSQgChEpnD5",
        "outputId": "ba0314a6-f41b-4c78-89df-66c1305dbd1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Patient age quantile  Hematocrit  Hemoglobin  Platelets  Red blood Cells  \\\n",
            "0                      17    0.236515   -0.022340  -0.517413         0.102004   \n",
            "1                       1   -1.571682   -0.774212   1.429667        -0.850035   \n",
            "2                       9   -0.747693   -0.586244  -0.429480        -1.361315   \n",
            "3                      11    0.991838    0.792188   0.072992         0.542763   \n",
            "4                       9    0.190738   -0.147652  -0.668155        -0.127191   \n",
            "..                    ...         ...         ...        ...              ...   \n",
            "595                    19    0.190738    0.165628  -0.102873         0.384090   \n",
            "596                    19   -0.289922   -0.523588   0.663397         0.754327   \n",
            "597                    15    0.717175    1.105468  -0.492289         0.613284   \n",
            "598                    17   -3.242548   -2.779203  -1.773594        -3.318285   \n",
            "599                    19    0.694287    0.541564  -0.906829         0.578024   \n",
            "\n",
            "     Lymphocytes  Leukocytes  Eosinophils  Monocytes  Neutrophils  \\\n",
            "0       0.318366   -0.094610     1.482158   0.357547    -0.619086   \n",
            "1      -0.005738    0.364550     1.018625   0.068652    -0.127395   \n",
            "2      -1.114514   -0.884923    -0.666950   1.276759     0.880570   \n",
            "3       0.045436   -0.211488    -0.709090  -0.220244     0.265957   \n",
            "4       0.002791   -1.132592    -0.709090   2.012129    -0.422410   \n",
            "..           ...         ...          ...        ...          ...   \n",
            "595    -1.583611   -0.328365     0.892207   1.066653     1.118221   \n",
            "596    -1.532437    1.569499    -0.540532   1.670707     1.134611   \n",
            "597     0.002791   -0.550988    -0.709090   0.909074    -0.061837   \n",
            "598    -1.830953   -1.733675    -0.582671   1.381812     1.552548   \n",
            "599    -0.295726   -1.288428    -0.835508   0.567652     0.380685   \n",
            "\n",
            "     Proteina C reativa mg/dL  \n",
            "0                   -0.147895  \n",
            "1                   -0.286986  \n",
            "2                    0.000000  \n",
            "3                   -0.487674  \n",
            "4                    0.000000  \n",
            "..                        ...  \n",
            "595                  3.627427  \n",
            "596                  5.733660  \n",
            "597                  0.561468  \n",
            "598                  0.609157  \n",
            "599                 -0.503570  \n",
            "\n",
            "[600 rows x 11 columns]\n",
            "0      0\n",
            "1      0\n",
            "2      0\n",
            "3      0\n",
            "4      0\n",
            "      ..\n",
            "595    0\n",
            "596    0\n",
            "597    0\n",
            "598    0\n",
            "599    1\n",
            "Name: Label, Length: 600, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)"
      ],
      "metadata": {
        "id": "NLK3yAcOppVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyswarm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlACMKH6qCZQ",
        "outputId": "c91352e0-4879-43e8-cc4f-4922bfac2a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyswarm\n",
            "  Downloading pyswarm-0.6.tar.gz (4.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyswarm) (1.21.6)\n",
            "Building wheels for collected packages: pyswarm\n",
            "  Building wheel for pyswarm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyswarm: filename=pyswarm-0.6-py3-none-any.whl size=4481 sha256=4fba39719a8d1cbc21e24eb37f2b038fb87dc58c5f06267911a14de19314d079\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/69/65/926e9c51b9fa99757cb43e8f6b74c5e6bb8b41a038b35c2db1\n",
            "Successfully built pyswarm\n",
            "Installing collected packages: pyswarm\n",
            "Successfully installed pyswarm-0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier, RandomForestRegressor\n",
        "from sklearn.svm import SVR, SVC\n",
        "\n",
        "\n",
        "# Base class of models\n",
        "class Model:\n",
        "    def __init__(self, params, X_train, X_test, y_train, y_test, loss_func, model):\n",
        "        self.params = params\n",
        "        self.X_train = X_train\n",
        "        self.X_test = X_test\n",
        "        self.y_train = y_train\n",
        "        self.y_test = y_test\n",
        "        self.loss_func = loss_func\n",
        "        self.model = model\n",
        "\n",
        "    # Method to get hyperparam type\n",
        "    def get_types(self, param):\n",
        "        pass\n",
        "\n",
        "    # Given a key and a value, this methods returns a random value of a\n",
        "    # specific hyperparam\n",
        "    def get_params(self, key, value):\n",
        "        pass\n",
        "\n",
        "    # Generates initial model hyperparams\n",
        "    def generate_params_model(self):\n",
        "        p = []\n",
        "\n",
        "        for i in self.params.keys():\n",
        "            num = self.get_params(i, self.params[i])\n",
        "            p.append(num)\n",
        "\n",
        "        return p\n",
        "\n",
        "    # Train a model and returns some loss function value\n",
        "    def fit(self, params):\n",
        "        params_dict = {}\n",
        "\n",
        "        for i, key in enumerate(self.params.keys()):\n",
        "            params_dict[key] = self.get_types(key)(params[i])\n",
        "\n",
        "        model = self.model(**params_dict)\n",
        "        model.fit(self.X_train, self.y_train)\n",
        "\n",
        "        y_pred = model.predict(self.X_test)\n",
        "        loss = self.loss_func(self.y_test, y_pred)\n",
        "\n",
        "        return loss, model\n",
        "\n",
        "\n",
        "class GradientBoosting(Model):\n",
        "    def get_types(self, param):\n",
        "        types = {\n",
        "            'n_estimators': np.int64,\n",
        "            'max_depth': np.int64,\n",
        "            'learning_rate': np.float64,\n",
        "            'tol': np.float64,\n",
        "        }\n",
        "\n",
        "        return types[param]\n",
        "\n",
        "    def get_params(self, key, value):\n",
        "        low = value[0]\n",
        "        high = value[1]\n",
        "\n",
        "        params = {\n",
        "            'n_estimators': np.random.randint(low, high + 1),\n",
        "            'max_depth': np.random.randint(low, high + 1),\n",
        "            'learning_rate': np.random.uniform(low, high),\n",
        "            'tol': np.random.uniform(low, high),\n",
        "        }\n",
        "\n",
        "        return params[key]\n",
        "\n",
        "\n",
        "class Bagging(Model):\n",
        "    def get_types(self, param):\n",
        "        types = {\n",
        "            'n_estimators': np.int64,\n",
        "        }\n",
        "\n",
        "        return types[param]\n",
        "\n",
        "    def get_params(self, key, value):\n",
        "        low = value[0]\n",
        "        high = value[1]\n",
        "\n",
        "        params = {\n",
        "            'n_estimators': np.random.randint(low, high + 1),\n",
        "            \n",
        "        }\n",
        "\n",
        "        return params[key]\n",
        "\n",
        "\n",
        "class SupportVectorMachines(Model):\n",
        "    def get_types(self, param):\n",
        "        types = {\n",
        "            'C': np.float64,\n",
        "            'tol': np.float64\n",
        "        }\n",
        "\n",
        "        return types[param]\n",
        "\n",
        "    def get_params(self, key, value):\n",
        "        low = value[0]\n",
        "        high = value[1]\n",
        "\n",
        "        params = {\n",
        "            'C': np.random.uniform(low, high),\n",
        "            'tol': np.random.uniform(low, high),\n",
        "        }\n",
        "\n",
        "        return params[key]\n",
        "\n",
        "\n",
        "def set_model(m, params, X_train, X_test, y_train, y_test, loss_func):\n",
        "    if isinstance(m, GradientBoostingRegressor):\n",
        "        model = GradientBoosting(params, X_train, X_test, y_train, y_test, loss_func, GradientBoostingRegressor)\n",
        "    elif isinstance(m, GradientBoostingClassifier):\n",
        "        model = GradientBoosting(params, X_train, X_test, y_train, y_test, loss_func, GradientBoostingClassifier)\n",
        "    elif isinstance(m, SVR):\n",
        "        model = SupportVectorMachines(params, X_train, X_test, y_train, y_test, loss_func, SVR)\n",
        "    elif isinstance(m, SVC):\n",
        "        model = SupportVectorMachines(params, X_train, X_test, y_train, y_test, loss_func, SVC)\n",
        "    elif isinstance(m, BaggingClassifier ):\n",
        "        model = Bagging(params, X_train, X_test, y_train, y_test, loss_func, BaggingClassifier)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "rvTC91lQqIiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#from pso2.models import set_model\n",
        "\n",
        "\n",
        "class Particle:\n",
        "    def __init__(self, parameters, identifier):\n",
        "        self.identifier = identifier            # Particle identifier\n",
        "        self.position_i = parameters            # Particle position\n",
        "        self.velocity_i = []                    # Particle velocity\n",
        "        self.pos_best_i = []                    # Best position individual\n",
        "        self.err_best_i = -1                    # Best error individual\n",
        "        self.err_i = -1                         # Error individual\n",
        "        self.model_i = None                     # Model individual\n",
        "        self.num_dimensions = len(parameters)   # Num of problem dimensions\n",
        "\n",
        "        # Generating initial velocities randomly\n",
        "        for i in range(0, self.num_dimensions):\n",
        "            v = np.random.rand(1)[0]\n",
        "            self.velocity_i.append(v)\n",
        "\n",
        "    def print_particle(self):\n",
        "        print('particle_{}: {}'.format(self.identifier, self.position_i))\n",
        "\n",
        "    def print_loss(self):\n",
        "        print('loss_{}: {}'.format(self.identifier, self.err_i))\n",
        "\n",
        "    # Evaluate current fitness\n",
        "    def evaluate(self, model):\n",
        "        self.err_i, self.model_i = model.fit(self.position_i)\n",
        "\n",
        "        # Check to see if the current position is an individual best\n",
        "        if self.err_i < self.err_best_i or self.err_best_i == -1:\n",
        "            self.pos_best_i = copy.deepcopy(self.position_i)\n",
        "            self.err_best_i = self.err_i\n",
        "\n",
        "    # Update new particle velocity\n",
        "    def update_velocity(self, pos_best_g, c1, c2, w):\n",
        "        \"\"\"\n",
        "        w: Constant inertia weight (how much to weigh the previous velocity)\n",
        "        c1: Cognitive constant\n",
        "        c2: Social constant\n",
        "        \"\"\"\n",
        "\n",
        "        for i in range(0, self.num_dimensions):\n",
        "            r1 = np.random.rand(1)[0]\n",
        "            r2 = np.random.rand(1)[0]\n",
        "\n",
        "            cognitive_vel = c1 * r1 * (self.pos_best_i[i] - self.position_i[i])\n",
        "            social_vel = c2 * r2 * (pos_best_g[i] - self.position_i[i])\n",
        "\n",
        "            self.velocity_i[i] = w * self.velocity_i[i] + cognitive_vel + social_vel\n",
        "\n",
        "    # Update the particle position based off new velocity updates\n",
        "    def update_position(self, boundaries):\n",
        "        for i in range(0, self.num_dimensions):\n",
        "            self.position_i[i] = self.position_i[i] + self.velocity_i[i]\n",
        "\n",
        "            # Adjust maximum position if necessary\n",
        "            if self.position_i[i] > boundaries[i][1]:\n",
        "                self.position_i[i] = boundaries[i][1]\n",
        "\n",
        "            # Adjsut minimum position if necessary\n",
        "            if self.position_i[i] < boundaries[i][0]:\n",
        "                self.position_i[i] = boundaries[i][0]\n",
        "\n",
        "\n",
        "class PSO:\n",
        "    def __init__(self, **params):\n",
        "        self.c1 = params.get('c1')\n",
        "        self.c2 = params.get('c2')\n",
        "        self.w = params.get('w')\n",
        "        self.max_iter = params.get('max_iter')\n",
        "        self.n_pop = params.get('n_pop')\n",
        "        self.boundaries = params.get('boundaries')\n",
        "        self.loss_func = params.get('loss_func')\n",
        "        self.verbose = params.get('verbose')\n",
        "\n",
        "        self.err_best_g = -1        # Best error for group\n",
        "        self.pos_best_g = []        # Best position for group\n",
        "        self.model_best_g = None    # Best model for group\n",
        "        self.best_params_ = {}\n",
        "\n",
        "        # Machine Learning model\n",
        "        self.model = set_model(\n",
        "            m=params.get('model'),\n",
        "            params=params.get('boundaries'),\n",
        "            X_train=params.get('X_train'),\n",
        "            X_test=params.get('X_test'),\n",
        "            y_train=params.get('y_train'),\n",
        "            y_test=params.get('y_test'),\n",
        "            loss_func=params.get('loss_func')\n",
        "        )\n",
        "\n",
        "        # Establish the swarm\n",
        "        self.swarm = []\n",
        "        for i in range(0, self.n_pop):\n",
        "            p = self.model.generate_params_model()\n",
        "            particle = Particle(p, i)\n",
        "            self.swarm.append(particle)\n",
        "\n",
        "    def optimize(self):\n",
        "        init = time.time()\n",
        "\n",
        "        i = 0\n",
        "\n",
        "        # Begin optimization loop\n",
        "        while i < self.max_iter:\n",
        "            if self.verbose:\n",
        "                print('iter_{}'.format(i))\n",
        "\n",
        "            # Cycle through particles in swarm and evaluate fitness\n",
        "            for j in range(0, self.n_pop):\n",
        "                self.swarm[j].evaluate(self.model)\n",
        "\n",
        "                if self.verbose == 2:\n",
        "                    self.swarm[j].print_loss()\n",
        "                    self.swarm[j].print_particle()\n",
        "\n",
        "                # Determine if current particle is the best (globally)\n",
        "                if self.swarm[j].err_i < self.err_best_g or self.err_best_g == -1:\n",
        "                    self.pos_best_g = copy.deepcopy(self.swarm[j].position_i)\n",
        "                    self.err_best_g = self.swarm[j].err_i\n",
        "                    self.model_best_g = copy.deepcopy(self.swarm[j].model_i)\n",
        "\n",
        "            # Cycle through swarm and update velocities and positions\n",
        "            for j in range(0, self.n_pop):\n",
        "                self.swarm[j].update_velocity(self.pos_best_g, self.c1, self.c2, self.w)\n",
        "                self.swarm[j].update_position(list(self.boundaries.values()))\n",
        "\n",
        "            if self.verbose:\n",
        "                print('best loss: {}'.format(self.err_best_g))\n",
        "\n",
        "            i += 1\n",
        "\n",
        "        end = time.time()\n",
        "\n",
        "        if self.verbose:\n",
        "            print('total time: {:.2f}s'.format(end - init))\n",
        "\n",
        "        self.best_params_ = self.format_output()\n",
        "\n",
        "        return self.model_best_g\n",
        "\n",
        "    def format_output(self):\n",
        "        output = {}\n",
        "\n",
        "        for i, key in enumerate(self.boundaries.keys()):\n",
        "            output[key] = self.model.get_types(key)(self.pos_best_g[i])\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "BRTTrqymqUHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#from pso2.optimizer import PSO\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load and dataprep\n",
        "    \n",
        "\n",
        "    # Model\n",
        "    model = GradientBoostingRegressor()\n",
        "\n",
        "    # Boundaries\n",
        "    boundaries = {\n",
        "        'n_estimators': (10, 200),\n",
        "        'max_depth': (3, 15),\n",
        "        'learning_rate': (0.001, 0.1)\n",
        "    }\n",
        "\n",
        "    # Function to minimize (or maximize)\n",
        "    loss_func = mean_squared_error\n",
        "\n",
        "    # PSO params\n",
        "    c1 = 1.0\n",
        "    c2 = 2.0\n",
        "    w = 0.5\n",
        "    n_pop = 10\n",
        "    max_iter = 10\n",
        "\n",
        "    # Compress all parameters into a dict\n",
        "    pso_params = {\n",
        "        'model': model,\n",
        "        'boundaries': boundaries,\n",
        "        'loss_func': loss_func,\n",
        "        'X_train': X_train,\n",
        "        'X_test': X_test,\n",
        "        'y_train': y_train,\n",
        "        'y_test': y_test,\n",
        "        'c1': c1,\n",
        "        'c2': c2,\n",
        "        'w': w,\n",
        "        'n_pop': n_pop,\n",
        "        'max_iter': max_iter,\n",
        "        'verbose': 1,\n",
        "    }\n",
        "\n",
        "    opt = PSO(**pso_params)\n",
        "    opt.optimize()\n",
        "    print(opt.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYeevlJZqgyi",
        "outputId": "54c03486-db2f-4ff7-f610-a18672e24f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter_0\n",
            "best loss: 0.05973965940891693\n",
            "iter_1\n",
            "best loss: 0.059675854208935925\n",
            "iter_2\n",
            "best loss: 0.059675854208935925\n",
            "iter_3\n",
            "best loss: 0.059675854208935925\n",
            "iter_4\n",
            "best loss: 0.05940926330737765\n",
            "iter_5\n",
            "best loss: 0.05928679090767192\n",
            "iter_6\n",
            "best loss: 0.05928679090767192\n",
            "iter_7\n",
            "best loss: 0.0590419917616937\n",
            "iter_8\n",
            "best loss: 0.0590419917616937\n",
            "iter_9\n",
            "best loss: 0.0590419917616937\n",
            "total time: 19.50s\n",
            "{'n_estimators': 137, 'max_depth': 3, 'learning_rate': 0.1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#from pso2.optimizer import PSO\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load and dataprep\n",
        "    \n",
        "\n",
        "    # Model\n",
        "    model = GradientBoostingClassifier()\n",
        "\n",
        "    # Boundaries\n",
        "    boundaries = {\n",
        "        'n_estimators': (10, 200),\n",
        "        'max_depth': (3, 15),\n",
        "        'learning_rate': (0.001, 0.1)\n",
        "    }\n",
        "\n",
        "    # Function to minimize (or maximize)\n",
        "    loss_func = mean_squared_error\n",
        "\n",
        "    # PSO params\n",
        "    c1 = 1.0\n",
        "    c2 = 2.0\n",
        "    w = 0.5\n",
        "    n_pop = 10\n",
        "    max_iter = 10\n",
        "\n",
        "    # Compress all parameters into a dict\n",
        "    pso_params = {\n",
        "        'model': model,\n",
        "        'boundaries': boundaries,\n",
        "        'loss_func': loss_func,\n",
        "        'X_train': X_train,\n",
        "        'X_test': X_test,\n",
        "        'y_train': y_train,\n",
        "        'y_test': y_test,\n",
        "        'c1': c1,\n",
        "        'c2': c2,\n",
        "        'w': w,\n",
        "        'n_pop': n_pop,\n",
        "        'max_iter': max_iter,\n",
        "        'verbose': 1,\n",
        "    }\n",
        "\n",
        "    opt = PSO(**pso_params)\n",
        "    opt.optimize()\n",
        "    print(opt.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "369hKm2BvhB8",
        "outputId": "51cfb046-10fd-4932-9e4c-0f3422a62be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter_0\n",
            "best loss: 0.075\n",
            "iter_1\n",
            "best loss: 0.06666666666666667\n",
            "iter_2\n",
            "best loss: 0.058333333333333334\n",
            "iter_3\n",
            "best loss: 0.058333333333333334\n",
            "iter_4\n",
            "best loss: 0.058333333333333334\n",
            "iter_5\n",
            "best loss: 0.058333333333333334\n",
            "iter_6\n",
            "best loss: 0.058333333333333334\n",
            "iter_7\n",
            "best loss: 0.058333333333333334\n",
            "iter_8\n",
            "best loss: 0.058333333333333334\n",
            "iter_9\n",
            "best loss: 0.058333333333333334\n",
            "total time: 16.63s\n",
            "{'n_estimators': 69, 'max_depth': 3, 'learning_rate': 0.1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GradientBoostingClassifier(n_estimators = 69, max_depth = 3, learning_rate= 0.1,random_state=8)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test , y_pred),\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pyg0c3c0vyJ3",
        "outputId": "d4160323-fd74-4a97-f05d-d6d30ee0875d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.97       106\n",
            "           1       0.82      0.64      0.72        14\n",
            "\n",
            "    accuracy                           0.94       120\n",
            "   macro avg       0.89      0.81      0.84       120\n",
            "weighted avg       0.94      0.94      0.94       120\n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#from pso2.optimizer import PSO\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load and dataprep\n",
        "    \n",
        "\n",
        "    # Model\n",
        "    model = RandomForestRegressor()\n",
        "\n",
        "    # Boundaries\n",
        "    boundaries = {\n",
        "        'n_estimators': (10, 200),\n",
        "        'max_depth': (3, 15),\n",
        "        #'learning_rate': (0.001, 0.1)\n",
        "    }\n",
        "\n",
        "    # Function to minimize (or maximize)\n",
        "    loss_func = mean_squared_error\n",
        "\n",
        "    # PSO params\n",
        "    c1 = 1.0\n",
        "    c2 = 2.0\n",
        "    w = 0.5\n",
        "    n_pop = 10\n",
        "    max_iter = 10\n",
        "\n",
        "    # Compress all parameters into a dict\n",
        "    pso_params = {\n",
        "        'model': model,\n",
        "        'boundaries': boundaries,\n",
        "        'loss_func': loss_func,\n",
        "        'X_train': X_train,\n",
        "        'X_test': X_test,\n",
        "        'y_train': y_train,\n",
        "        'y_test': y_test,\n",
        "        'c1': c1,\n",
        "        'c2': c2,\n",
        "        'w': w,\n",
        "        'n_pop': n_pop,\n",
        "        'max_iter': max_iter,\n",
        "        'verbose': 1,\n",
        "    }\n",
        "\n",
        "    opt = PSO(**pso_params)\n",
        "    opt.optimize()\n",
        "    print(opt.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI1SjEA3rNTC",
        "outputId": "aa210497-a0e9-4285-a1f3-58a6ac6d5abb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter_0\n",
            "best loss: 0.059670546615611574\n",
            "iter_1\n",
            "best loss: 0.059663145535878113\n",
            "iter_2\n",
            "best loss: 0.059663145535878113\n",
            "iter_3\n",
            "best loss: 0.058913098058070726\n",
            "iter_4\n",
            "best loss: 0.058913098058070726\n",
            "iter_5\n",
            "best loss: 0.05888149946562917\n",
            "iter_6\n",
            "best loss: 0.05888149946562917\n",
            "iter_7\n",
            "best loss: 0.05888149946562917\n",
            "iter_8\n",
            "best loss: 0.05888149946562917\n",
            "iter_9\n",
            "best loss: 0.05888149946562917\n",
            "total time: 14.09s\n",
            "{'n_estimators': 60, 'max_depth': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#from pso2.optimizer import PSO\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load and dataprep\n",
        "    \n",
        "\n",
        "    # Model\n",
        "    model = RandomForestClassifier()\n",
        "\n",
        "    # Boundaries\n",
        "    boundaries = {\n",
        "        'n_estimators': (10, 200),\n",
        "        'max_depth': (3, 15),\n",
        "        #'learning_rate': (0.001, 0.1)\n",
        "    }\n",
        "\n",
        "    # Function to minimize (or maximize)\n",
        "    loss_func = mean_squared_error\n",
        "\n",
        "    # PSO params\n",
        "    c1 = 1.0\n",
        "    c2 = 2.0\n",
        "    w = 0.5\n",
        "    n_pop = 10\n",
        "    max_iter = 10\n",
        "\n",
        "    # Compress all parameters into a dict\n",
        "    pso_params = {\n",
        "        'model': model,\n",
        "        'boundaries': boundaries,\n",
        "        'loss_func': loss_func,\n",
        "        'X_train': X_train,\n",
        "        'X_test': X_test,\n",
        "        'y_train': y_train,\n",
        "        'y_test': y_test,\n",
        "        'c1': c1,\n",
        "        'c2': c2,\n",
        "        'w': w,\n",
        "        'n_pop': n_pop,\n",
        "        'max_iter': max_iter,\n",
        "        'verbose': 1,\n",
        "    }\n",
        "\n",
        "    opt = PSO(**pso_params)\n",
        "    opt.optimize()\n",
        "    print(opt.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M4Ue4_Cr4aq",
        "outputId": "69c336ab-0d3a-4180-aafd-181a012ffc1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter_0\n",
            "best loss: 0.08333333333333333\n",
            "iter_1\n",
            "best loss: 0.058333333333333334\n",
            "iter_2\n",
            "best loss: 0.058333333333333334\n",
            "iter_3\n",
            "best loss: 0.058333333333333334\n",
            "iter_4\n",
            "best loss: 0.058333333333333334\n",
            "iter_5\n",
            "best loss: 0.058333333333333334\n",
            "iter_6\n",
            "best loss: 0.058333333333333334\n",
            "iter_7\n",
            "best loss: 0.058333333333333334\n",
            "iter_8\n",
            "best loss: 0.058333333333333334\n",
            "iter_9\n",
            "best loss: 0.058333333333333334\n",
            "total time: 28.46s\n",
            "{'n_estimators': 150, 'max_depth': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators = 150, max_depth = 3,random_state=8)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test , y_pred),\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0788aZLHwf86",
        "outputId": "52708552-bf91-41b4-812f-e0f9bc740df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95       106\n",
            "           1       1.00      0.21      0.35        14\n",
            "\n",
            "    accuracy                           0.91       120\n",
            "   macro avg       0.95      0.61      0.65       120\n",
            "weighted avg       0.92      0.91      0.88       120\n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#from pso2.optimizer import PSO\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load and dataprep\n",
        "    \n",
        "\n",
        "    # Model\n",
        "    model = AdaBoostClassifier()\n",
        "\n",
        "    # Boundaries\n",
        "    boundaries = {\n",
        "        'n_estimators': (10, 200),\n",
        "        'max_depth': (3, 15),\n",
        "        #'learning_rate': (0.001, 0.1)\n",
        "    }\n",
        "\n",
        "    # Function to minimize (or maximize)\n",
        "    loss_func = mean_squared_error\n",
        "\n",
        "    # PSO params\n",
        "    c1 = 1.0\n",
        "    c2 = 2.0\n",
        "    w = 0.5\n",
        "    n_pop = 10\n",
        "    max_iter = 10\n",
        "\n",
        "    # Compress all parameters into a dict\n",
        "    pso_params = {\n",
        "        'model': model,\n",
        "        'boundaries': boundaries,\n",
        "        'loss_func': loss_func,\n",
        "        'X_train': X_train,\n",
        "        'X_test': X_test,\n",
        "        'y_train': y_train,\n",
        "        'y_test': y_test,\n",
        "        'c1': c1,\n",
        "        'c2': c2,\n",
        "        'w': w,\n",
        "        'n_pop': n_pop,\n",
        "        'max_iter': max_iter,\n",
        "        'verbose': 1,\n",
        "    }\n",
        "\n",
        "    opt = PSO(**pso_params)\n",
        "    opt.optimize()\n",
        "    print(opt.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiY_VJfxsavE",
        "outputId": "8a5462c1-54a2-4892-86f1-cc30e3e31be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter_0\n",
            "best loss: 0.058333333333333334\n",
            "iter_1\n",
            "best loss: 0.058333333333333334\n",
            "iter_2\n",
            "best loss: 0.058333333333333334\n",
            "iter_3\n",
            "best loss: 0.058333333333333334\n",
            "iter_4\n",
            "best loss: 0.058333333333333334\n",
            "iter_5\n",
            "best loss: 0.058333333333333334\n",
            "iter_6\n",
            "best loss: 0.058333333333333334\n",
            "iter_7\n",
            "best loss: 0.058333333333333334\n",
            "iter_8\n",
            "best loss: 0.058333333333333334\n",
            "iter_9\n",
            "best loss: 0.058333333333333334\n",
            "total time: 27.44s\n",
            "{'n_estimators': 150, 'max_depth': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#from pso2.optimizer import PSO\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load and dataprep\n",
        "    \n",
        "\n",
        "    # Model\n",
        "    model = AdaBoostClassifier()\n",
        "\n",
        "    # Boundaries\n",
        "    boundaries = {\n",
        "        'n_estimators': (10, 200),\n",
        "        'max_depth': (3, 15),\n",
        "        'learning_rate': (0.001, 0.1)\n",
        "    }\n",
        "\n",
        "    # Function to minimize (or maximize)\n",
        "    loss_func = mean_squared_error\n",
        "\n",
        "    # PSO params\n",
        "    c1 = 1.0\n",
        "    c2 = 2.0\n",
        "    w = 0.5\n",
        "    n_pop = 10\n",
        "    max_iter = 10\n",
        "\n",
        "    # Compress all parameters into a dict\n",
        "    pso_params = {\n",
        "        'model': model,\n",
        "        'boundaries': boundaries,\n",
        "        'loss_func': loss_func,\n",
        "        'X_train': X_train,\n",
        "        'X_test': X_test,\n",
        "        'y_train': y_train,\n",
        "        'y_test': y_test,\n",
        "        'c1': c1,\n",
        "        'c2': c2,\n",
        "        'w': w,\n",
        "        'n_pop': n_pop,\n",
        "        'max_iter': max_iter,\n",
        "        'verbose': 1,\n",
        "    }\n",
        "\n",
        "    opt = PSO(**pso_params)\n",
        "    opt.optimize()\n",
        "    print(opt.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD0ynfOAs5Bx",
        "outputId": "e0fed6b7-8f24-4f02-8f8a-652b835e2a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter_0\n",
            "best loss: 0.06666666666666667\n",
            "iter_1\n",
            "best loss: 0.06666666666666667\n",
            "iter_2\n",
            "best loss: 0.058333333333333334\n",
            "iter_3\n",
            "best loss: 0.058333333333333334\n",
            "iter_4\n",
            "best loss: 0.058333333333333334\n",
            "iter_5\n",
            "best loss: 0.058333333333333334\n",
            "iter_6\n",
            "best loss: 0.058333333333333334\n",
            "iter_7\n",
            "best loss: 0.058333333333333334\n",
            "iter_8\n",
            "best loss: 0.058333333333333334\n",
            "iter_9\n",
            "best loss: 0.058333333333333334\n",
            "total time: 20.48s\n",
            "{'n_estimators': 82, 'max_depth': 3, 'learning_rate': 0.05384606852207195}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AdaBoostClassifier(n_estimators = 82, learning_rate = 0.05384606852207195,random_state=8)\n",
        "#96 0.06897974961663625\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test , y_pred),\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKE4jTMfxzZ-",
        "outputId": "8cda78e4-baf4-42d9-d20d-873b7b041098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95       106\n",
            "           1       0.71      0.36      0.48        14\n",
            "\n",
            "    accuracy                           0.91       120\n",
            "   macro avg       0.82      0.67      0.71       120\n",
            "weighted avg       0.90      0.91      0.89       120\n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#from pso2.optimizer import PSO\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load and dataprep\n",
        "    \n",
        "\n",
        "    # Model\n",
        "    model = XGBClassifier()\n",
        "\n",
        "    # Boundaries\n",
        "    boundaries = {\n",
        "        'n_estimators': (10, 200),\n",
        "        'max_depth': (3, 15),\n",
        "        'learning_rate': (0.001, 0.1)\n",
        "    }\n",
        "\n",
        "    # Function to minimize (or maximize)\n",
        "    loss_func = mean_squared_error\n",
        "\n",
        "    # PSO params\n",
        "    c1 = 1.0\n",
        "    c2 = 2.0\n",
        "    w = 0.5\n",
        "    n_pop = 10\n",
        "    max_iter = 10\n",
        "\n",
        "    # Compress all parameters into a dict\n",
        "    pso_params = {\n",
        "        'model': model,\n",
        "        'boundaries': boundaries,\n",
        "        'loss_func': loss_func,\n",
        "        'X_train': X_train,\n",
        "        'X_test': X_test,\n",
        "        'y_train': y_train,\n",
        "        'y_test': y_test,\n",
        "        'c1': c1,\n",
        "        'c2': c2,\n",
        "        'w': w,\n",
        "        'n_pop': n_pop,\n",
        "        'max_iter': max_iter,\n",
        "        'verbose': 1,\n",
        "    }\n",
        "\n",
        "    opt = PSO(**pso_params)\n",
        "    opt.optimize()\n",
        "    print(opt.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYz1xM86uafq",
        "outputId": "d7489752-0027-4dcc-9267-8dbf262587f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter_0\n",
            "best loss: 0.08333333333333333\n",
            "iter_1\n",
            "best loss: 0.06666666666666667\n",
            "iter_2\n",
            "best loss: 0.06666666666666667\n",
            "iter_3\n",
            "best loss: 0.058333333333333334\n",
            "iter_4\n",
            "best loss: 0.058333333333333334\n",
            "iter_5\n",
            "best loss: 0.058333333333333334\n",
            "iter_6\n",
            "best loss: 0.058333333333333334\n",
            "iter_7\n",
            "best loss: 0.058333333333333334\n",
            "iter_8\n",
            "best loss: 0.058333333333333334\n",
            "iter_9\n",
            "best loss: 0.058333333333333334\n",
            "total time: 19.96s\n",
            "{'n_estimators': 96, 'max_depth': 3, 'learning_rate': 0.06897974961663625}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBClassifier(n_estimators = 96, learning_rate = 0.06897974961663625,max_depth=3,random_state=8)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test , y_pred),\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmTRfmrtyUoV",
        "outputId": "7de47038-2f1e-4c6a-f682-7258ca5b2b5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95       106\n",
            "           1       0.64      0.64      0.64        14\n",
            "\n",
            "    accuracy                           0.92       120\n",
            "   macro avg       0.80      0.80      0.80       120\n",
            "weighted avg       0.92      0.92      0.92       120\n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#from pso2.optimizer import PSO\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load and dataprep\n",
        "    \n",
        "\n",
        "    # Model\n",
        "    model = XGBClassifier()\n",
        "\n",
        "    # Boundaries\n",
        "    boundaries = {\n",
        "        'n_estimators': (10, 200),\n",
        "        'max_depth': (3, 15),\n",
        "        'learning_rate': (0.001, 0.1)\n",
        "    }\n",
        "\n",
        "    # Function to minimize (or maximize)\n",
        "    loss_func = mean_squared_error\n",
        "\n",
        "    # PSO params\n",
        "    c1 = 1.0\n",
        "    c2 = 2.0\n",
        "    w = 0.5\n",
        "    n_pop = 10\n",
        "    max_iter = 10\n",
        "\n",
        "    # Compress all parameters into a dict\n",
        "    pso_params = {\n",
        "        'model': model,\n",
        "        'boundaries': boundaries,\n",
        "        'loss_func': loss_func,\n",
        "        'X_train': X_train,\n",
        "        'X_test': X_test,\n",
        "        'y_train': y_train,\n",
        "        'y_test': y_test,\n",
        "        'c1': c1,\n",
        "        'c2': c2,\n",
        "        'w': w,\n",
        "        'n_pop': n_pop,\n",
        "        'max_iter': max_iter,\n",
        "        'verbose': 1,\n",
        "    }\n",
        "\n",
        "    opt = PSO(**pso_params)\n",
        "    opt.optimize()\n",
        "    print(opt.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVvk3PcvzSmp",
        "outputId": "5f83e050-bc5b-4a36-b04a-eff8447b149f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter_0\n",
            "best loss: 0.058333333333333334\n",
            "iter_1\n",
            "best loss: 0.058333333333333334\n",
            "iter_2\n",
            "best loss: 0.058333333333333334\n",
            "iter_3\n",
            "best loss: 0.05\n",
            "iter_4\n",
            "best loss: 0.05\n",
            "iter_5\n",
            "best loss: 0.05\n",
            "iter_6\n",
            "best loss: 0.05\n",
            "iter_7\n",
            "best loss: 0.05\n",
            "iter_8\n",
            "best loss: 0.05\n",
            "iter_9\n",
            "best loss: 0.05\n",
            "total time: 5.24s\n",
            "{'n_estimators': 15, 'max_depth': 13, 'learning_rate': 0.09721381442041677}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBClassifier(n_estimators = 15, learning_rate = 0.09721381442041677,max_depth=13,random_state=8)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test , y_pred),\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToCWPanWzWk4",
        "outputId": "ec9e3e81-e6ea-4f0e-8ee9-1152a7afc38b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       106\n",
            "           1       0.83      0.71      0.77        14\n",
            "\n",
            "    accuracy                           0.95       120\n",
            "   macro avg       0.90      0.85      0.87       120\n",
            "weighted avg       0.95      0.95      0.95       120\n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#from pso2.optimizer import PSO\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load and dataprep\n",
        "    \n",
        "\n",
        "    # Model\n",
        "    model = AdaBoostClassifier()\n",
        "\n",
        "    # Boundaries\n",
        "    boundaries = {\n",
        "        'n_estimators': (10, 200),\n",
        "        'learning_rate': (0.001, 0.1)\n",
        "    }\n",
        "\n",
        "    # Function to minimize (or maximize)\n",
        "    loss_func = mean_squared_error\n",
        "\n",
        "    # PSO params\n",
        "    c1 = 1.0\n",
        "    c2 = 2.0\n",
        "    w = 0.5\n",
        "    n_pop = 10\n",
        "    max_iter = 10\n",
        "\n",
        "    # Compress all parameters into a dict\n",
        "    pso_params = {\n",
        "        'model': model,\n",
        "        'boundaries': boundaries,\n",
        "        'loss_func': loss_func,\n",
        "        'X_train': X_train,\n",
        "        'X_test': X_test,\n",
        "        'y_train': y_train,\n",
        "        'y_test': y_test,\n",
        "        'c1': c1,\n",
        "        'c2': c2,\n",
        "        'w': w,\n",
        "        'n_pop': n_pop,\n",
        "        'max_iter': max_iter,\n",
        "        'verbose': 1,\n",
        "    }\n",
        "\n",
        "    opt = PSO(**pso_params)\n",
        "    opt.optimize()\n",
        "    print(opt.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcFA0qLi0Dp5",
        "outputId": "bccff5b4-bc37-4369-dc04-a5944a7e920c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter_0\n",
            "best loss: 0.08333333333333333\n",
            "iter_1\n",
            "best loss: 0.08333333333333333\n",
            "iter_2\n",
            "best loss: 0.08333333333333333\n",
            "iter_3\n",
            "best loss: 0.08333333333333333\n",
            "iter_4\n",
            "best loss: 0.08333333333333333\n",
            "iter_5\n",
            "best loss: 0.08333333333333333\n",
            "iter_6\n",
            "best loss: 0.08333333333333333\n",
            "iter_7\n",
            "best loss: 0.08333333333333333\n",
            "iter_8\n",
            "best loss: 0.08333333333333333\n",
            "iter_9\n",
            "best loss: 0.08333333333333333\n",
            "total time: 15.19s\n",
            "{'n_estimators': 74, 'learning_rate': 0.08921146119789608}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AdaBoostClassifier(n_estimators = 74, learning_rate = 0.08921146119789608,random_state=8)\n",
        "#40 0.1 92\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test , y_pred),\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pLI73sO0x5x",
        "outputId": "dd38b080-5009-4cb5-dff6-6058956535ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.95       106\n",
            "           1       0.75      0.43      0.55        14\n",
            "\n",
            "    accuracy                           0.92       120\n",
            "   macro avg       0.84      0.70      0.75       120\n",
            "weighted avg       0.91      0.92      0.91       120\n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#from pso2.optimizer import PSO\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load and dataprep\n",
        "    \n",
        "\n",
        "    # Model\n",
        "    model = RandomForestClassifier()\n",
        "\n",
        "    # Boundaries\n",
        "    boundaries = {\n",
        "        'n_estimators': (10, 200),\n",
        "        'max_depth': (3, 15),\n",
        "        #'learning_rate': (0.001, 0.1)\n",
        "    }\n",
        "\n",
        "    # Function to minimize (or maximize)\n",
        "    loss_func = mean_squared_error\n",
        "\n",
        "    # PSO params\n",
        "    c1 = 1.0\n",
        "    c2 = 2.0\n",
        "    w = 0.5\n",
        "    n_pop = 10\n",
        "    max_iter = 10\n",
        "\n",
        "    # Compress all parameters into a dict\n",
        "    pso_params = {\n",
        "        'model': model,\n",
        "        'boundaries': boundaries,\n",
        "        'loss_func': loss_func,\n",
        "        'X_train': X_train,\n",
        "        'X_test': X_test,\n",
        "        'y_train': y_train,\n",
        "        'y_test': y_test,\n",
        "        'c1': c1,\n",
        "        'c2': c2,\n",
        "        'w': w,\n",
        "        'n_pop': n_pop,\n",
        "        'max_iter': max_iter,\n",
        "        'verbose': 1,\n",
        "    }\n",
        "\n",
        "    opt = PSO(**pso_params)\n",
        "    opt.optimize()\n",
        "    print(opt.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PasFW6Lh08sG",
        "outputId": "40e4dfb2-2b6c-422e-e3f0-d18cd37e31fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter_0\n",
            "best loss: 0.06666666666666667\n",
            "iter_1\n",
            "best loss: 0.06666666666666667\n",
            "iter_2\n",
            "best loss: 0.06666666666666667\n",
            "iter_3\n",
            "best loss: 0.06666666666666667\n",
            "iter_4\n",
            "best loss: 0.058333333333333334\n",
            "iter_5\n",
            "best loss: 0.058333333333333334\n",
            "iter_6\n",
            "best loss: 0.058333333333333334\n",
            "iter_7\n",
            "best loss: 0.058333333333333334\n",
            "iter_8\n",
            "best loss: 0.058333333333333334\n",
            "iter_9\n",
            "best loss: 0.058333333333333334\n",
            "total time: 12.18s\n",
            "{'n_estimators': 59, 'max_depth': 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators = 59, max_depth = 8,random_state=8)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test , y_pred),\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Txhwb8uR1Pbz",
        "outputId": "93b1a0c7-2591-4eee-d945-cb995a839008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       106\n",
            "           1       0.88      0.50      0.64        14\n",
            "\n",
            "    accuracy                           0.93       120\n",
            "   macro avg       0.91      0.75      0.80       120\n",
            "weighted avg       0.93      0.93      0.93       120\n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#from pso2.optimizer import PSO\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load and dataprep\n",
        "    \n",
        "\n",
        "    # Model\n",
        "    model = BaggingClassifier()\n",
        "\n",
        "    # Boundaries\n",
        "    boundaries = {\n",
        "        'n_estimators': (10, 200),\n",
        "    }\n",
        "\n",
        "    # Function to minimize (or maximize)\n",
        "    loss_func = mean_squared_error\n",
        "\n",
        "    # PSO params\n",
        "    c1 = 1.0\n",
        "    c2 = 2.0\n",
        "    w = 0.5\n",
        "    n_pop = 10\n",
        "    max_iter = 10\n",
        "\n",
        "    # Compress all parameters into a dict\n",
        "    pso_params = {\n",
        "        'model': model,\n",
        "        'boundaries': boundaries,\n",
        "        'loss_func': loss_func,\n",
        "        'X_train': X_train,\n",
        "        'X_test': X_test,\n",
        "        'y_train': y_train,\n",
        "        'y_test': y_test,\n",
        "        'c1': c1,\n",
        "        'c2': c2,\n",
        "        'w': w,\n",
        "        'n_pop': n_pop,\n",
        "        'max_iter': max_iter,\n",
        "        'verbose': 1,\n",
        "    }\n",
        "\n",
        "    opt = PSO(**pso_params)\n",
        "    opt.optimize()\n",
        "    print(opt.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I7MA4T82vRh",
        "outputId": "b728a0cc-b824-4e2c-db0e-4649098c702e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter_0\n",
            "best loss: 0.06666666666666667\n",
            "iter_1\n",
            "best loss: 0.058333333333333334\n",
            "iter_2\n",
            "best loss: 0.058333333333333334\n",
            "iter_3\n",
            "best loss: 0.058333333333333334\n",
            "iter_4\n",
            "best loss: 0.058333333333333334\n",
            "iter_5\n",
            "best loss: 0.058333333333333334\n",
            "iter_6\n",
            "best loss: 0.058333333333333334\n",
            "iter_7\n",
            "best loss: 0.058333333333333334\n",
            "iter_8\n",
            "best loss: 0.058333333333333334\n",
            "iter_9\n",
            "best loss: 0.058333333333333334\n",
            "total time: 27.35s\n",
            "{'n_estimators': 75}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BaggingClassifier(n_estimators = 75,random_state=8)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test , y_pred),\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kPRHqN_5Zvj",
        "outputId": "06f755d5-a09e-4127-cc1c-cca3953f0c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.96       106\n",
            "           1       0.73      0.57      0.64        14\n",
            "\n",
            "    accuracy                           0.93       120\n",
            "   macro avg       0.84      0.77      0.80       120\n",
            "weighted avg       0.92      0.93      0.92       120\n",
            " \n",
            "\n"
          ]
        }
      ]
    }
  ]
}